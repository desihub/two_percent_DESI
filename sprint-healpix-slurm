#!/usr/bin/env python

"""Wrapper script on sprint-healpix which generates individual SLURM scripts

nside area/deg2
2 859.436692696
4 214.859173174
8 53.7147932935
16 13.4286983234
32 3.35717458084
64 0.839293645211
128 0.209823411303
256 0.0524558528257
512 0.0131139632064

From Jaime: "It took 98 nodes, each node used 24 cores for 3 hours. That gives
us 7K core hours in total. In wall clock time, taking into account the queue
delays, it took ~24 hours to run. (edited)"

From Stephen: "The nested scheme is such that the super pixel for each pixel is
a bit shift of 2 bits, i.e. integer division by 4.  So going up 3 layers from 64
-> 32 -> 16 -> 8 is pixnum // (4**3)"

Additional comments from Stephen:

    output_dir/8-{superpix}/64-{pixnum}/filename-64-{pixnum}.fits

    where pixnum is the nside=64 nested pixel number, and superpix = pixnum // 4**3.

    I'm not completely convinced that will be user friendly, but it does have
    the advantages that:

    * <1000 subdirectories at any level
    
    * everything under a 8-{superpix} subdirectory is grouped on the sky (unlike
      the case if we just did subdir = pixnum // 100 or something like that that
      is easier to calculate in your head but breaks spatial grouping).

    * nside=8 is 53.7 deg2 which seems likely for a viable sub-unit to process
      at NERSC per job

    * nside=64 is 0.84 deg2 which seems like a viable sized sub-unit for
      grouping targets

"""
from __future__ import print_function, division

import os
import argparse

import numpy as np
import healpy as hp
from astropy.table import Table

from desimodel.footprint import tiles2pix
from desispec.log import get_logger
log = get_logger()

def main():

    parser = argparse.ArgumentParser()
    parser.add_argument('--topdir', help='Top-level output directory.', type=str, default='./')
    parser.add_argument('--config', '-c', default='input.yaml')
    parser.add_argument('--seed', '-s', help='Top-level seed for random number generation', type=int, default=None)
    parser.add_argument('--nproc', type=int, help='number of concurrent processes to use', default=24)
    parser.add_argument('--nside-spectra', help='Resolution of the healpixels passed to targets_truth', type=int, default=16)
    parser.add_argument('--nside-output-dir', help='Resolution of the healpixels used to organize the output files', type=int, default=8)
    parser.add_argument('--nsuperpix-per-node', help='Number of serial superpixels to assign to each NERSC node', type=int, default=6)
#   parser.add_argument('--nsuperpix-per-node', help='Number of nside-output-dir healpixels to process per NERSC node', type=int, default=4)
    args = parser.parse_args()

    # Read the pointings in the 2% survey and assign healpixels.
    env = 'TWOPCT_DIR'
    if env not in os.environ:
        log.fatal('Required ${} environment variable not set'.format(env))
        raise EnvironmentError('Required ${} environment variable not set'.format(env))
    
    twopctfile = os.path.join(os.getenv('TWOPCT_DIR'), 'twopct.ecsv')
    log.info('Reading {}'.format(twopctfile))
    twopct = Table.read(twopctfile, format='ascii.ecsv', guess=False)
    healpixels = tiles2pix(nside=args.nside_spectra, tiles=twopct)

    # Generate the vector of input seeds.
    rand = np.random.RandomState(args.seed)
    healseeds = rand.randint(2**32, size=len(healpixels))

    # Group the (smaller) healpixels into superpixels for the high-level
    # organization of the output directories.
    superfactor = np.int( np.log2(args.nside_spectra / args.nside_output_dir) ) # scale factor
    allsuperpix = healpixels // 4**superfactor
    superpix = np.unique(allsuperpix)
    nsuperpix = len(superpix)

    nnode = np.int( np.ceil(nsuperpix / args.nsuperpix_per_node) )
    superchunk = np.array_split(superpix, nnode)

    log.info('Processing spectra in healpixels with nside = {}.'.format(args.nside_spectra))
    log.info('Number of superpixels (output directories) = {} with nside = {}.'.format(nsuperpix, args.nside_output_dir))
    log.info('Number of nodes needed = {} with {} superpixels (= {:.3f} deg2) per node.'.format(
        nnode, args.nsuperpix_per_node, args.nsuperpix_per_node * hp.nside2pixarea(args.nside_output_dir, degrees=True)))

    # Generate a SLURM script for each superpixel.
    for pix in superchunk:

        slurmfile = os.path.join( args.topdir, 'slurm-{}-{}.sh'.format(args.nside_output_dir, '-'.join(pix.astype(str))) )
        log.info('Writing {}'.format(slurmfile))

        slurm = open(slurmfile, 'w')
        slurm.write('#!/bin/bash\n')
        slurm.write('#SBATCH -p debug\n')
        slurm.write('#SBATCH -N 1\n')
        slurm.write('#SBATCH -L SCRATCH,project\n')
        slurm.write('#SBATCH -t 00:30:00\n')
        slurm.write('\n')

        for thispix in pix:
            prefix = '{}-{}'.format(args.nside_output_dir, thispix)
            output_dir = os.path.join(args.topdir, prefix)

            these = np.where(thispix == allsuperpix)[0]
            log.info('  Number of healpixels (nside = {}) = {} in superpixel {} (nside = {}) with total area = {:.3f} deg2.'.format(
                args.nside_spectra, len(these), thispix, args.nside_output_dir, 
                len(these) * hp.nside2pixarea(args.nside_spectra, degrees=True)))
            
            for smallpix, smallseed in zip(healpixels[these], healseeds[these]):
                slurm.write('time srun -N 1 -n 1 -c {} python  sprint-healpix '.format(args.nproc))
                slurm.write('--config {} '.format(args.config))
                slurm.write('--nproc {} '.format(args.nproc))
                slurm.write('--output_dir {} '.format(output_dir))
                slurm.write('--seed {} '.format(smallseed))
                slurm.write('--nside {} '.format(args.nside_spectra))
                slurm.write('--healpixels {} & \n'.format(smallpix))
                #slurm.write('--healpixels {}\n'.format( ' '.join(healpixels[these].astype(str))))
            slurm.write('wait')

        slurm.close()

if __name__ == '__main__':
    main()
    
